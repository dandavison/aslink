#+startup: hideblocks

* Introduction
  The output from the Solexa pipeline is a file containing
  around 5 x 10^6 sequence reads, each about 20-80 bp long. These
  correspond to multiple genomic loci in multiple individuals. A given
  locus in a given individual may have many different reads. Thus
  variation between the different sequences is due to
  1. Non-homology of sequences
  2. Polymorphism
  3. Sequencing error

  The task is to cluster the 5 million sequences so that all members
  of a given cluster represent the same locus, and so that no
  sequences representing the same locus are members of different
  clusters.

  There is one sequence read per line; the top of the file looks like
  this

#+begin_example 
yakuba:/data/shared/Hpy_parsed_as_Nde> h combined
CAAATACCAATTTTGCATGATCAATGCTTGCTTGATTTTATATCAATATGTTTATGCTTATATTTCAT
AAGGTGCAGAAAACTTTTTGGTTTAAAACCAAAAATTTTTCTATAATCATACA
TTAAACAATGCCTGCACCACACCAATTAAATAAAAAAGTGCTATTCTTATTTAAAACTCCTGTGTATA
TTCACCCCTCTTGATAGGTAATGTTTTATTGCTAATTACATGCATACA
GTGATGAATGTGTCAAAGAGAATGGCAAAAGTCTCCTGTTAGTATGNTTGAAAAAAGATCTTGATGTG
TGAACCTTGAGGAACCCCGGAAGTAACAACATACC
CGGCCTTGTCATCCTGAGTTCGATTGGTCCGGACAAGAGTAAACACGTGATGGATTACGACATACAAC
TAACAAATGTATCAATCATAAATGATTTTTGTGTGTTTAATTAACATACCTGGATCGGAGAGAGGTTC
TCATGGAGTTTTAAAATCTTATCTTAAAGTTATAGAAATTAAAAAAACACTGTGTATGAGTAGTGTAA
CAACTCGTTCAAGTCAAATCACTGTTATCAATTTACATCACTGCAAACATCCAACGCCATTAAAATAG
#+end_example

* Read sequences into R
#+begin_src R
  read.sequences <- function(file) {
      cat(date(), "\tReading sequences")
      x <- scan(file, what="", quiet=TRUE)
      x <- strsplit(x, "")
      cat("\n")
      
      lengths <- sapply(x, length)
      min.length <- min(lengths)
      cat(date(), "\tDiscarding all but initial", min.length, "bases")
      x <- lapply(x, "[", 1:min.length)
      cat("\n")
      
      cat(date(), "\tConverting to matrix format (each column is one sequence)")
      ## x <- matrix(as.integer(unlist(x)), ncol=nseqs, nrow=min.length)
      x <- matrix(unlist(x), nrow=length(x), ncol=min.length, byrow=TRUE)
      cat("\n")
      
      x
  }
#+end_src


#+begin_src R 
  library(RColorBrewer, lib="~/lib/R")
  library(TraMineR, lib="~/lib/R")
  
  file <- "/data/shared/Hpy_parsed_as_Nde/combined"
  x <- read.sequences(pipe(sprintf("head -n 10000 < %s", file)))
  x <- x[,1:20]
  sx <- seqdef(x)
  dx <- seqdist(sx, method="HAM", with.miss=TRUE, full.matrix=FALSE)
  summary(dx)
#+end_src

* Simple clustering in C
*** Algorithm
  This C code implements the following algorithm:
  
#+begin_src python
  for each sequence:
      for each canonical_sequence:
          if sequence is close to canonical sequence:
              assign sequence to that cluster
      if sequence is unassigned:
          make sequence canonical representative of new cluster
#+end_src
  
  In this algorithm, when we create a new cluster, we know that the
  canonical sequence is not "close" to any of the other canonical
  sequences.

  *However* it is possible that
  1. A new canonical sequence is "close" to an assigned non-canonical
     sequence.
  2. A newly assigned sequence is similar to sequences in other
     clusters (either canonical or non-canonical).

  So the algorithm is not correct in general. But it should work well
  when different loci have very different sequences.

*** C code
#+begin_src C :tangle quickclust.c
  #include <stdlib.h>
  #include <stdio.h>
  #include <assert.h>
  #include <unistd.h>
  #include <stdarg.h>
  
  void usage() ;
  void ERROR(char *fmt, ...) ;
  void *memcpy(void *dest, const void *src, size_t n);
  ssize_t getline(char **lineptr, size_t *n, FILE *stream);
  
  int main(int argc, char **argv) {
      char *item=NULL ;           /* getline automatically mallocs and reallocs line */
      size_t maxlinelength=0 ;    /*    and increments maxlinelength */
      // int maxitems = 1 ;          /* number of allocated items */
      int maxK = 1 ;              /* number of allocated canonical sequences */
      int i, c, d, k, K, nchars=-1, maxd=-1, seqlen ;
      int cluster ;
      // int *cluster = (int *) malloc(maxitems * sizeof(int)) ;
      char **canonical_member = (char **) malloc(maxK * sizeof(char *)) ;
  
      while((c = getopt(argc, argv, "c:d:")) != -1) {
          switch(c) {
          case 'c': nchars = atoi(optarg) ; break ;
          case 'd': maxd = atoi(optarg) ; break ;
          case '?': usage() ;
          }
      }
      if(nchars <= 0 || maxd < 0) usage() ;
      
      i = K = 0 ;
      while( (seqlen = getline(&item, &maxlinelength, stdin)) > 0 ) {
          if( --seqlen < nchars )
              ERROR("Line %d has %d characters (should be at least %d)\n", i, seqlen, nchars) ;
          if(i % 1000 == 0) fprintf(stderr, "%6d\r", i) ;
          
          for(cluster = -1, k = 0 ; k < K ; k++) {
              for(d = 0, c = 0 ; c < nchars ; c++)
                  if(item[c] != canonical_member[k][c]) d++ ; 
              if( d <= maxd ) { cluster = k ; break ; }
          }
          if(cluster == -1) {
              cluster = K ;
              canonical_member[K] = (char *) malloc(nchars * sizeof(char)) ;
              memcpy(canonical_member[K], item, nchars * sizeof(char)) ;
              if(++K > maxK) {
                  maxK *= 2 ;
                  canonical_member = realloc(canonical_member, maxK * sizeof(char *)) ;
              }
          }
          printf("%d\n", cluster + 1) ;
          i++ ;
      }
      // for(k = 0 ; k < K ; k++) free(canonical_member[k]) ;
      // free(canonical_member) ;
      return 0 ;
  }
  
  void ERROR(char *fmt, ...) {
      va_list args;
  
      fflush(stderr);
      
      va_start(args, fmt);
      vfprintf(stderr, fmt, args);
      va_end(args);
      
      fflush(stderr) ;
      exit(2) ;
  }
  
  void usage() {
      ERROR("quickclust -c numchars -d maxdiff") ;
  }
#+end_src

*** Makefile
#+begin_src makefile :tangle makefile
  CFLAGS = -O2 -Wall
  all:    quickclust
#+end_src
*** Timing
| code                             |    seqs |  c | d | clusters found | outfile        |      time |
|----------------------------------+---------+----+---+----------------+----------------+-----------|
| vanilla                          |     1e4 | 20 | 5 |           4439 | clusters-0-1e4 |     0.435 |
| vanilla                          |     1e5 | 20 | 5 |          12070 | clusters-0-1e5 |       7.4 |
| check seqlen & progress          |     1e5 | 20 | 5 |          12070 |                |       7.6 |
| check seqlen progress every 1000 |         |    |   |                |                |       7.3 |
|                                  | 5288915 |    |   |          69655 |                | ~ 10 mins |
*** Validation
***** Compare results with reversed input

#+begin_src sh
tac ../combined > combined-reversed
quickclust -c 20 -d 4 < combined-reversed | tac > clusters-all-c20-d4-rev
#+end_src

* Split input into clusters
*** R
#+begin_src R 
  file <- "/data/shared/Hpy_parsed_as_Nde/combined"
  x <- scan(file, what="", quiet=TRUE)
  split.sequences <- function(x, clusters) {
      for(i in unique(clusters)) {
          if(i %% 100 == 0) cat(i, "\r")
          cat(x[clusters == i], sep="\n", file=file.path("clusters", sprintf("%05d", i)))
      }
      cat("\n")
      
      x
  }
#+end_src
*** sed
    This is too slow
#+begin_src sh
  #!/bin/bash
  mkdir -p clusters
  i=1
  combined=/data/shared/Hpy_parsed_as_Nde/combined
  while read cluster ; do
      sed -n ${i}p < $combined >> clusters/$cluster
      echo $i
      (( i += 1 ))
  done
#+end_src


* An incomplete attempt in R
    The idea here was to use various sorting heuristics, eliminate
    duplicate sequences that occur consecutively in the sorted output,
    and thus end up with a manageable number of sequences to cluster.

    I was considering forming the lower-triangle of the full distance
    matrix using dist(), and then applying a hierarchical clustering
    method using hclust() and identifying clusters at some similarity
    threshold using cutree(). But I am concerned that dist/hclust will
    be hopelessly slow, and decided to investigate straightforward
    solutions in C first.

#+begin_src R
  cluster.sequences <- function(file, thresh) {
      nseqs <- as.integer(system(paste("wc -l <", file), intern=TRUE))
      ans <- rep(NA, nseqs)
  
      ## file <- pipe(sprintf("tr 'AGCT' '1234' < %s", file))
  
      x <- read.sequences(file)
      nas <- rep(NA, nrow(x))
      distances <- function(x) {
          ax <- cbind(nas, x)
          bx <- cbind(x, nas)
          d <- abs(colSums(ax - bx)) / min.length
          d[-c(1,ncol(ax))]
      }
      
      cat(date(), "\tComputing distances between consecutive sequences")
      close <- rle(distances(x) < thresh)
      
      cat("\n")
  
      
      close
  }
#+end_src
